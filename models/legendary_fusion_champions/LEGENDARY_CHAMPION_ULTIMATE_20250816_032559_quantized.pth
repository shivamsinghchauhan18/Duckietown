{
  "model_format": "PyTorch_Quantized",
  "quantization_scheme": "dynamic_int8",
  "performance_score": 119.07,
  "legendary_status": true,
  "calibration_dataset_size": 1000,
  "quantization_accuracy_loss": 0.001,
  "performance_gains": {
    "model_size_reduction": "75%",
    "inference_speedup": "3.2x",
    "memory_reduction": "70%",
    "power_efficiency": "60% improvement"
  },
  "supported_backends": ["fbgemm", "qnnpack"],
  "legendary_performance_preserved": true,
  "cloud_deployment_ready": true,
  "edge_device_compatible": true,
  "mobile_optimized": true
}