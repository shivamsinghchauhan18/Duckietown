# üèÜ COMPETITIVE CHAMPION TRAINING CONFIGURATION üèÜ
# Ultimate configuration for world-class autonomous driving performance

# Training Configuration
training:
  # Extended training for champion-level performance
  total_episodes: 5000
  max_episode_steps: 1000
  
  # Frequent evaluation for competitive benchmarking
  evaluation_interval: 100
  evaluation_episodes: 20
  
  # Regular checkpointing for safety
  checkpoint_interval: 250
  keep_checkpoints_num: 10
  
  # Champion-level evaluation
  champion_evaluation_episodes: 100
  competitive_threshold: 85.0

# Environment Configuration (Physical World Optimized)
environment:
  # High-resolution observations for detailed perception
  camera_width: 240
  camera_height: 160
  
  # Advanced physics simulation
  physics_steps_per_frame: 2
  physics_accuracy: "high"
  
  # Domain randomization for robustness
  domain_randomization:
    enabled: true
    lighting_variation: 0.3
    texture_variation: 0.2
    physics_variation: 0.1
    weather_effects: true
  
  # Progressive track complexity
  track_complexity: "progressive"
  dynamic_obstacles: true
  weather_conditions: true
  
  # Competitive environment settings
  max_steps: 1000
  accept_start_angle_deg: 2  # Tighter tolerance
  
  # Multi-environment for diverse training
  num_envs: 8
  
  # Advanced map selection
  maps:
    - "loop_empty"
    - "small_loop"
    - "zigzag_dists"
    - "4way"
    - "udem1"
    - "straight_road"

# Algorithm Configuration (Champion-Level PPO)
algorithm:
  name: "PPO"
  
  # Advanced network architecture
  model:
    # Enhanced CNN for high-resolution input
    conv_filters: [32, 64, 128, 256]
    conv_kernel_sizes: [8, 4, 3, 3]
    conv_strides: [4, 2, 1, 1]
    
    # Deep fully connected layers
    fc_hiddens: [512, 512, 256]
    
    # Advanced activation
    activation: "relu"
    
    # LSTM for temporal understanding
    use_lstm: true
    lstm_cell_size: 256
    
    # Attention mechanism
    use_attention: true
    attention_dim: 128
  
  # Champion-level hyperparameters
  hyperparameters:
    # Optimized learning rates
    lr: 1.0e-4
    lr_schedule: "cosine_annealing"
    
    # Large batch sizes for stability
    train_batch_size: 4096
    sgd_minibatch_size: 512
    num_sgd_iter: 15
    
    # PPO-specific optimizations
    clip_param: 0.15  # Tighter clipping for stability
    vf_clip_param: 5.0
    entropy_coeff: 0.005  # Reduced for more deterministic policy
    vf_loss_coeff: 0.25
    
    # Advanced advantage estimation
    use_gae: true
    lambda: 0.98  # Higher for better long-term planning
    gamma: 0.995  # Higher discount for future rewards
    
    # Gradient optimization
    grad_clip: 0.3
    max_grad_norm: 0.5
    
    # KL divergence control
    kl_coeff: 0.1
    kl_target: 0.005  # Tighter KL constraint

# Curriculum Learning (Champion Path)
curriculum:
  enabled: true
  adaptive: true
  
  stages:
    - name: "Foundation"
      episodes: 800
      description: "Perfect basic lane following"
      difficulty: 0.3
      success_criteria:
        avg_reward: 120
        collision_rate: 0.15
        lane_accuracy: 0.85
      env_config:
        domain_randomization: false
        weather_conditions: false
        dynamic_obstacles: false
        track_complexity: "simple"
    
    - name: "Intermediate"
      episodes: 1200
      description: "Advanced maneuvers with light randomization"
      difficulty: 0.5
      success_criteria:
        avg_reward: 180
        collision_rate: 0.08
        lane_accuracy: 0.90
      env_config:
        domain_randomization: true
        weather_conditions: false
        dynamic_obstacles: false
        track_complexity: "moderate"
    
    - name: "Advanced"
      episodes: 1500
      description: "Complex scenarios with weather"
      difficulty: 0.7
      success_criteria:
        avg_reward: 240
        collision_rate: 0.04
        lane_accuracy: 0.93
      env_config:
        domain_randomization: true
        weather_conditions: true
        dynamic_obstacles: false
        track_complexity: "complex"
    
    - name: "Expert"
      episodes: 1000
      description: "Dynamic obstacles and full complexity"
      difficulty: 0.85
      success_criteria:
        avg_reward: 280
        collision_rate: 0.02
        lane_accuracy: 0.95
      env_config:
        domain_randomization: true
        weather_conditions: true
        dynamic_obstacles: true
        track_complexity: "expert"
    
    - name: "Champion"
      episodes: 500
      description: "Ultimate challenge - physical world preparation"
      difficulty: 1.0
      success_criteria:
        avg_reward: 320
        collision_rate: 0.01
        lane_accuracy: 0.97
      env_config:
        domain_randomization: true
        weather_conditions: true
        dynamic_obstacles: true
        track_complexity: "champion"
        physical_world_sim: true

# Advanced Reward Configuration
rewards:
  # Multi-objective reward with competitive weights
  
  # Primary objectives (70% total weight)
  lane_following:
    weight: 0.25
    enabled: true
    precision_bonus: true
    
  speed_optimization:
    weight: 0.20
    enabled: true
    target_speed: 1.8  # Aggressive but safe
    consistency_bonus: true
    
  safety_performance:
    weight: 0.25
    enabled: true
    collision_penalty: -5.0
    near_miss_penalty: -1.0
    
  # Secondary objectives (20% total weight)
  smoothness:
    weight: 0.10
    enabled: true
    steering_smoothness: true
    throttle_smoothness: true
    
  efficiency:
    weight: 0.10
    enabled: true
    fuel_efficiency: true
    time_efficiency: true
  
  # Advanced objectives (10% total weight)
  cornering_performance:
    weight: 0.05
    enabled: true
    apex_hitting: true
    exit_speed: true
    
  overtaking:
    weight: 0.03
    enabled: true
    safe_overtaking: true
    
  lane_changing:
    weight: 0.02
    enabled: true
    smooth_transitions: true

# Competitive Benchmarking
benchmarking:
  enabled: true
  
  # Performance thresholds
  thresholds:
    beginner: 30
    intermediate: 50
    advanced: 70
    expert: 85
    champion: 95
  
  # Competitive metrics
  metrics:
    - "lap_time"
    - "collision_rate"
    - "lane_accuracy"
    - "speed_consistency"
    - "cornering_performance"
    - "overtaking_success"
    - "fuel_efficiency"
  
  # Real-time comparison
  live_comparison: true
  leaderboard: true

# Advanced Logging
logging:
  log_level: "INFO"
  log_interval: 50
  
  # Comprehensive logging
  tensorboard:
    enabled: true
    log_dir: "logs/champion_training"
    log_images: true
    log_histograms: true
    
  # Weights & Biases integration
  wandb:
    enabled: true
    project: "duckietown-champion"
    entity: "competitive-ai"
    tags: ["champion", "physical-world", "competitive"]
  
  # Advanced metrics logging
  advanced_logging:
    enabled: true
    log_gradients: true
    log_activations: true
    log_attention_maps: true
    log_policy_entropy: true
    log_value_estimates: true
    
  # Performance profiling
  profiling:
    enabled: true
    profile_interval: 1000
    memory_profiling: true
    gpu_profiling: false  # CPU training

# System Configuration (Optimized for Performance)
system:
  # CPU optimization for maximum performance
  num_cpus: 0  # Use all available
  num_gpus: 0
  
  # Memory management for large-scale training
  object_store_memory: 4000000000  # 4GB
  
  # Ray configuration for distributed training
  ray_config:
    ignore_reinit_error: true
    include_dashboard: true
    dashboard_port: 8265
    
  # Advanced optimizations
  optimization:
    use_multiprocessing: true
    multiprocessing_method: "spawn"
    pin_memory: true
    num_workers: 4
    
  # Debugging and monitoring
  debug_mode: false
  verbose: true
  monitoring_interval: 10

# Physical World Transfer Optimization
physical_world:
  # Sim-to-real transfer techniques
  domain_adaptation:
    enabled: true
    reality_gap_compensation: true
    sensor_noise_modeling: true
    actuator_delay_modeling: true
    
  # Hardware-specific optimizations
  hardware_optimization:
    raspberry_pi_compatible: true
    jetson_nano_compatible: true
    low_latency_inference: true
    
  # Deployment preparation
  deployment:
    model_quantization: true
    onnx_export: true
    tensorrt_optimization: false  # CPU deployment
    
  # Safety features for physical deployment
  safety:
    emergency_stop: true
    collision_avoidance: true
    speed_limiting: true
    human_override: true

# Evaluation Configuration
evaluation:
  # Comprehensive evaluation
  num_episodes: 100
  deterministic: true
  
  # Champion-level metrics
  champion_metrics:
    - "overall_performance_score"
    - "consistency_rating"
    - "safety_rating"
    - "efficiency_rating"
    - "robustness_rating"
    - "physical_world_readiness"
  
  # Stress testing
  stress_tests:
    enabled: true
    weather_stress: true
    lighting_stress: true
    obstacle_stress: true
    sensor_noise_stress: true
  
  # Competitive evaluation
  competitive_evaluation:
    enabled: true
    benchmark_comparison: true
    leaderboard_submission: true
    
  # Visualization
  render: false
  save_video: true
  video_quality: "high"
  
  # Analysis
  detailed_analysis: true
  performance_breakdown: true
  failure_analysis: true

# Model Export and Deployment
export:
  # Multiple format support
  formats:
    - "pytorch"
    - "onnx"
    - "tensorrt"
    - "tflite"
  
  # Optimization levels
  optimization_levels:
    - "speed"
    - "accuracy"
    - "balanced"
  
  # Hardware targets
  hardware_targets:
    - "raspberry_pi_4"
    - "jetson_nano"
    - "jetson_xavier"
    - "generic_cpu"
  
  # Deployment packages
  deployment_packages:
    docker: true
    ros_package: true
    standalone_executable: true