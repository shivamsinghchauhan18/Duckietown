# üîç Failure Analyzer Implementation Summary

## Overview

The **FailureAnalyzer** is a comprehensive failure analysis and diagnostic system that provides detailed failure classification, episode trace analysis, action pattern analysis, video recording, and spatial pattern visualization for reinforcement learning model evaluation in the Duckietown environment.

## Key Features

### üéØ Comprehensive Failure Classification
- **Collision Detection**: Static and dynamic obstacle collisions
- **Lane Departure**: Left and right lane departures with severity assessment
- **Stuck Behavior**: Detection of insufficient progress scenarios
- **Oscillation Detection**: Identification of excessive steering changes
- **Over-speed Violations**: Speed limit enforcement
- **Sensor Glitches**: Detection of observation inconsistencies
- **Slip/Oversteer Events**: Motion pattern analysis for vehicle dynamics issues

### üìä Episode Trace Analysis
- **State Capture**: Complete episode state traces with position, velocity, actions, and rewards
- **Action Histograms**: Statistical analysis of steering and throttle patterns
- **Lane Deviation Timelines**: Temporal analysis of lane-following performance
- **Performance Metrics**: Comprehensive episode-level performance calculations

### üé• Video Recording System
- **Worst Episode Recording**: Automatic video capture for failed or problematic episodes
- **Configurable Quality**: Multiple video quality settings for storage optimization
- **Smart Selection**: Intelligent episode selection based on failure severity and count

### üó∫Ô∏è Spatial Heatmap Generation
- **Lane Deviation Heatmaps**: Spatial visualization of lane-following performance
- **Failure Location Heatmaps**: Geographic distribution of failure events
- **Contact Point Analysis**: Collision location visualization
- **High-Resolution Mapping**: Configurable resolution for detailed analysis

### üìà Statistical Analysis
- **Failure Statistics**: Comprehensive failure type distributions and trends
- **Model Comparisons**: Cross-model failure pattern analysis
- **Environmental Correlations**: Failure analysis by map and test suite
- **Severity Assessment**: Failure impact classification and prioritization

## Architecture

### Core Components

```python
# Main analyzer class
FailureAnalyzer(config: FailureAnalysisConfig)

# Configuration management
FailureAnalysisConfig(
    stuck_threshold=0.1,
    oscillation_threshold=0.5,
    record_worst_k=5,
    heatmap_resolution=100
)

# Data structures
StateTrace(timestamp, position, velocity, lane_position, heading_error, action, reward)
FailureEvent(failure_type, severity, timestamp, position, description)
EpisodeTrace(episode_id, model_id, failure_events, state_trace, performance_metrics)
```

### Failure Classification System

```python
class FailureType(Enum):
    COLLISION_STATIC = "collision_static"
    COLLISION_DYNAMIC = "collision_dynamic"
    OFF_LANE_LEFT = "off_lane_left"
    OFF_LANE_RIGHT = "off_lane_right"
    STUCK = "stuck"
    OSCILLATION = "oscillation"
    OVER_SPEED = "over_speed"
    MISSED_STOP = "missed_stop"
    SENSOR_GLITCH = "sensor_glitch"
    SLIP_OVERSTEER = "slip_oversteer"
```

### Severity Levels

```python
class FailureSeverity(Enum):
    CRITICAL = "critical"    # Safety-critical failures
    HIGH = "high"           # Performance-degrading failures
    MEDIUM = "medium"       # Minor issues
    LOW = "low"            # Negligible issues
```

## Usage Examples

### Basic Episode Analysis

```python
from duckietown_utils.failure_analyzer import FailureAnalyzer, FailureAnalysisConfig

# Initialize analyzer
config = FailureAnalysisConfig(
    stuck_threshold=0.1,
    oscillation_threshold=0.5,
    record_worst_k=5
)
analyzer = FailureAnalyzer(config)

# Analyze episode
episode_trace = analyzer.analyze_episode(
    episode_result=episode_result,
    state_trace=state_trace,
    video_frames=video_frames  # Optional
)

print(f"Failures detected: {len(episode_trace.failure_events)}")
for failure in episode_trace.failure_events:
    print(f"  {failure.failure_type.value}: {failure.description}")
```

### Failure Statistics Generation

```python
# Generate comprehensive statistics
statistics = analyzer.generate_failure_statistics(model_ids=["model_v1", "model_v2"])

print(f"Success rate: {statistics['summary']['success_rate']:.1%}")
print("Failure distribution:")
for failure_type, count in statistics['failure_types'].items():
    print(f"  {failure_type}: {count}")
```

### Spatial Heatmap Generation

```python
# Generate heatmaps for specific map
heatmaps = analyzer.generate_spatial_heatmaps(
    map_name="loop_empty",
    model_ids=["model_v1"]
)

print("Generated heatmaps:")
for heatmap_type, path in heatmaps.items():
    print(f"  {heatmap_type}: {path}")
```

### Comprehensive Report Generation

```python
# Generate full analysis report
report = analyzer.generate_failure_report(model_ids=["model_v1"])

print("Report sections:")
for section in report.keys():
    print(f"  {section}")

# Access recommendations
for i, recommendation in enumerate(report['recommendations'], 1):
    print(f"{i}. {recommendation}")
```

## Configuration Options

### Detection Thresholds

```python
config = FailureAnalysisConfig(
    # Stuck behavior detection
    stuck_threshold=0.1,        # m/s minimum velocity
    stuck_duration=2.0,         # seconds
    
    # Oscillation detection
    oscillation_threshold=0.5,  # steering change threshold
    oscillation_window=10,      # steps to analyze
    
    # Speed monitoring
    overspeed_threshold=2.0,    # m/s maximum velocity
    
    # Lane monitoring
    lane_deviation_threshold=0.3  # meters from center
)
```

### Video Recording Settings

```python
config = FailureAnalysisConfig(
    record_worst_k=5,          # Number of worst episodes to record
    video_fps=30,              # Frames per second
    video_quality="high",      # 'low', 'medium', 'high'
)
```

### Heatmap Generation Settings

```python
config = FailureAnalysisConfig(
    heatmap_resolution=100,    # Pixels per meter
    heatmap_smoothing=0.1,     # Gaussian smoothing sigma
)
```

## Output Structure

### Directory Organization

```
logs/failure_analysis/
‚îú‚îÄ‚îÄ videos/                    # Episode video recordings
‚îÇ   ‚îú‚îÄ‚îÄ episode_001_20240101_120000.mp4
‚îÇ   ‚îî‚îÄ‚îÄ episode_002_20240101_120100.mp4
‚îú‚îÄ‚îÄ heatmaps/                  # Spatial analysis heatmaps
‚îÇ   ‚îú‚îÄ‚îÄ lane_deviation_heatmap_loop_empty_20240101_120000.png
‚îÇ   ‚îú‚îÄ‚îÄ failure_location_heatmap_loop_empty_20240101_120000.png
‚îÇ   ‚îî‚îÄ‚îÄ contact_point_heatmap_loop_empty_20240101_120000.png
‚îú‚îÄ‚îÄ traces/                    # Episode trace data
‚îÇ   ‚îú‚îÄ‚îÄ episode_001_trace.json
‚îÇ   ‚îî‚îÄ‚îÄ episode_002_trace.json
‚îú‚îÄ‚îÄ failure_statistics.json   # Comprehensive statistics
‚îî‚îÄ‚îÄ failure_analysis_report_20240101_120000.json  # Full report
```

### Report Structure

```json
{
  "report_metadata": {
    "generation_time": "2024-01-01T12:00:00",
    "analyzer_config": {...},
    "analyzed_models": ["model_v1"],
    "analyzed_maps": ["loop_empty"]
  },
  "failure_statistics": {
    "summary": {
      "total_episodes": 100,
      "failed_episodes": 15,
      "success_rate": 0.85,
      "total_failures": 23
    },
    "failure_types": {
      "collision_static": 8,
      "off_lane_left": 5,
      "stuck": 3,
      "oscillation": 7
    },
    "failure_by_model": {...},
    "failure_by_map": {...}
  },
  "spatial_analysis": {
    "heatmaps_generated": {...},
    "total_heatmaps": 6
  },
  "episode_summaries": [...],
  "recommendations": [
    "High collision rate with static obstacles (34.8% of failures). Consider improving object detection sensitivity.",
    "Frequent lane departures (21.7% of failures). Consider tuning lane-following reward weights."
  ]
}
```

## Integration with Evaluation System

### With Evaluation Orchestrator

```python
from duckietown_utils.evaluation_orchestrator import EvaluationOrchestrator
from duckietown_utils.failure_analyzer import FailureAnalyzer

# Initialize components
orchestrator = EvaluationOrchestrator(config)
analyzer = FailureAnalyzer(failure_config)

# Run evaluation with failure analysis
results = orchestrator.evaluate_models(model_paths)

# Analyze failures for each episode
for episode_result in results.episode_results:
    if episode_result.state_trace:  # If trace available
        episode_trace = analyzer.analyze_episode(
            episode_result,
            episode_result.state_trace,
            episode_result.video_frames
        )

# Generate comprehensive failure report
failure_report = analyzer.generate_failure_report()
```

### With Suite Manager

```python
from duckietown_utils.suite_manager import SuiteManager
from duckietown_utils.failure_analyzer import FailureAnalyzer

suite_manager = SuiteManager(config)
analyzer = FailureAnalyzer(failure_config)

# Run suite with failure analysis
suite_results = suite_manager.run_suite("stress", model, seeds)

# Analyze failures from suite
for episode_result in suite_results.episode_results:
    if not episode_result.success:  # Focus on failed episodes
        episode_trace = analyzer.analyze_episode(episode_result, state_trace)
```

## Performance Considerations

### Memory Management
- **Trace Storage**: State traces are stored in memory during analysis
- **Video Buffering**: Video frames are processed in batches to manage memory
- **Heatmap Generation**: Uses efficient numpy operations for spatial analysis

### Processing Speed
- **Parallel Analysis**: Episode analysis can be parallelized across multiple episodes
- **Lazy Loading**: Traces and videos are loaded on-demand
- **Efficient Algorithms**: Optimized failure detection algorithms for real-time analysis

### Storage Optimization
- **Selective Recording**: Only worst-performing episodes are recorded as videos
- **Compressed Traces**: Episode traces are stored in compressed JSON format
- **Configurable Retention**: Automatic cleanup of old analysis artifacts

## Testing and Validation

### Unit Tests
- **Failure Classification**: Tests for all failure type detection algorithms
- **Statistical Analysis**: Validation of statistical calculations and confidence intervals
- **Heatmap Generation**: Tests for spatial analysis and visualization
- **Video Recording**: Mock tests for video capture and encoding

### Integration Tests
- **End-to-End Analysis**: Complete episode analysis workflow testing
- **Multi-Model Analysis**: Cross-model comparison and statistics generation
- **Report Generation**: Comprehensive report creation and validation

### Performance Tests
- **Large Dataset Analysis**: Testing with hundreds of episodes
- **Memory Usage**: Monitoring memory consumption during analysis
- **Processing Speed**: Benchmarking analysis throughput

## Best Practices

### Configuration Tuning
1. **Threshold Adjustment**: Tune detection thresholds based on environment characteristics
2. **Video Selection**: Balance storage costs with diagnostic value
3. **Heatmap Resolution**: Choose resolution based on map size and detail requirements

### Analysis Workflow
1. **Incremental Analysis**: Analyze episodes as they complete rather than in batches
2. **Regular Reporting**: Generate periodic failure reports for trend analysis
3. **Comparative Analysis**: Compare failure patterns across different models and conditions

### Interpretation Guidelines
1. **Context Consideration**: Consider environmental conditions when interpreting failures
2. **Statistical Significance**: Use confidence intervals and significance testing
3. **Root Cause Analysis**: Combine multiple analysis methods for comprehensive understanding

## Future Enhancements

### Planned Features
- **Real-time Analysis**: Live failure detection during training
- **Predictive Analysis**: Early warning systems for potential failures
- **Interactive Visualization**: Web-based dashboard for failure analysis
- **Automated Recommendations**: AI-powered suggestions for model improvements

### Integration Opportunities
- **Training Integration**: Direct feedback to training algorithms
- **Deployment Monitoring**: Production failure monitoring and alerting
- **Comparative Benchmarking**: Cross-algorithm failure pattern analysis

## Conclusion

The FailureAnalyzer provides a comprehensive solution for understanding and diagnosing reinforcement learning model failures in autonomous driving scenarios. Its combination of automated failure detection, statistical analysis, spatial visualization, and intelligent reporting makes it an essential tool for model development, validation, and deployment in the Duckietown environment.

The system's modular design allows for easy integration with existing evaluation workflows while providing the flexibility to customize analysis parameters for specific research objectives and deployment requirements.